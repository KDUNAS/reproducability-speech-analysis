{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech analysis and re-synthesis\n",
    "\n",
    "This notebook demonstrates how to analyze speech and re-synthesis speech waveform from speech parameters using [pysptk](https://github.com/r9y9/pysptk) (and other useful speech/audio/music analysis packages). Synthesized audio examples are provided so that you are able to compare synthesis filters on your browser. \n",
    "\n",
    "Note: this notebook is a modified version of one linked on the [pysptk](https://github.com/r9y9/pysptk) github page.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- pysptk: https://github.com/r9y9/pysptk\n",
    "- scipy\n",
    "- librosa: https://github.com/bmcfee/librosa\n",
    "- seaborn: https://github.com/mwaskom/seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "seaborn.set(style=\"dark\")\n",
    "plt.rcParams['figure.figsize'] = (16, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pysptk\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, x = wavfile.read(pysptk.util.example_audio_file())\n",
    "assert sr == 16000\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(np.array(x, dtype=np.float64), sr=sr)\n",
    "plt.title(\"Raw waveform of example audio flle\")\n",
    "Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source parameter extraction\n",
    "\n",
    "### Framing and windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 1024\n",
    "hop_length = 80\n",
    "\n",
    "# Note that almost all of pysptk functions assume input array is C-contiguous and np.float4 element type\n",
    "frames = librosa.util.frame(x, frame_length=frame_length, hop_length=hop_length).astype(np.float64).T\n",
    "\n",
    "# Windowing\n",
    "frames *= pysptk.blackman(frame_length)\n",
    "\n",
    "assert frames.shape[1] == frame_length "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F0 estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F0 estimation\n",
    "f0 = pysptk.swipe(x.astype(np.float64), fs=sr, hopsize=hop_length, min=60, max=240, otype=\"f0\")\n",
    "plt.plot(f0, linewidth=3, label=\"F0 trajectory estimated by SWIPE'\")\n",
    "plt.xlim(0, len(f0))\n",
    "plt.legend(prop={'size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source excitation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that pysptk.excite assuems input as pitch, not *f0*.\n",
    "pitch = pysptk.swipe(x.astype(np.float64), fs=sr, hopsize=hop_length, min=60, max=240, otype=\"pitch\")\n",
    "source_excitation = pysptk.excite(pitch, hop_length)\n",
    "                            \n",
    "plt.plot(source_excitation, label=\"Source excitation\")\n",
    "plt.xlim(0, len(source_excitation))\n",
    "plt.ylim(-2, 16)\n",
    "plt.legend(prop={'size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to what that sounds like\n",
    "Audio(source_excitation, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis from mel-cepstrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order of mel-cepstrum\n",
    "order = 25\n",
    "alpha = 0.41\n",
    "\n",
    "mc = pysptk.mcep(frames, order, alpha)\n",
    "logH = pysptk.mgc2sp(mc, alpha, 0.0, frame_length).real\n",
    "librosa.display.specshow(logH.T, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectral envelope estimate from mel-cepstrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysptk.synthesis import MLSADF, Synthesizer\n",
    "\n",
    "# Convert mel-cesptrum to MLSADF coefficients\n",
    "b =pysptk.mc2b(mc, alpha);\n",
    "\n",
    "synthesizer = Synthesizer(MLSADF(order=order, alpha=alpha), hop_length)\n",
    "\n",
    "x_synthesized = synthesizer.synthesis(source_excitation, b)\n",
    "\n",
    "librosa.display.waveplot(x_synthesized, sr=sr)\n",
    "plt.title(\"Synthesized waveform by MLSADF\")\n",
    "Audio(x_synthesized, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some experiments\n",
    "\n",
    "* We can modify the original pitch track to get different effects\n",
    "* First scale the pitch by multiplying/dividing by a constant\n",
    "* Then replace all non-zero pitch values by a constant\n",
    "* Listen to the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = pysptk.swipe(x.astype(np.float64), fs=sr, hopsize=hop_length, min=60, max=240, otype=\"pitch\")\n",
    "\n",
    "# modify the pitch, note that pitch is the wavelength of the sound \n",
    "# in samples, so larger pitch is a lower frequency sound\n",
    "pitch = pitch*2\n",
    "\n",
    "source_excitation = pysptk.excite(pitch, hop_length)\n",
    "     \n",
    "x_synthesized = synthesizer.synthesis(source_excitation, b)\n",
    "\n",
    "librosa.display.waveplot(x_synthesized, sr=sr)\n",
    "plt.title(\"Synthesized waveform by MLSADF\")\n",
    "Audio(x_synthesized, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = pysptk.swipe(x.astype(np.float64), fs=sr, hopsize=hop_length, min=60, max=240, otype=\"pitch\")\n",
    "\n",
    "# modify the pitch to set it to be a constant value of 130\n",
    "# first generate an array of True/False to indicate when pitch is > 0 \n",
    "mask = pitch > 0\n",
    "# now set those values where pitch > 0 to be 130\n",
    "pitch[mask] = 130\n",
    "\n",
    "source_excitation = pysptk.excite(pitch, hop_length)\n",
    "     \n",
    "x_synthesized = synthesizer.synthesis(source_excitation, b)\n",
    "\n",
    "librosa.display.waveplot(x_synthesized, sr=sr)\n",
    "plt.title(\"Synthesized waveform by MLSADF\")\n",
    "Audio(x_synthesized, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resynthesise Yourself\n",
    "\n",
    "You can use any recording for this exercise, so record your own voice (needs to be recorded at 16KHz sampling frequency) and save it as a WAV file in the same directory as this notebook.  Then load it into the notebook in the __Data__ section at the top, eg.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, x = wavfile.read(\"your_speech_file.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then re-run the notebook from top to bottom to hear your own speech re-synthesised using this method.\n",
    "\n",
    "__NOTE:__ you may want to look at [Audacity](https://www.audacityteam.org/) for a sound recording tool that let's you control the sample frequency of your recordings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
